{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cchTu9-IbhOR"
   },
   "source": [
    "# <center>VAE-baseline for CIFAR10 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4FT-UfMbhOU"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31387,
     "status": "ok",
     "timestamp": 1526063425858,
     "user": {
      "displayName": "Lukas Mosser",
      "photoUrl": "//lh6.googleusercontent.com/-TeSv83-LAiI/AAAAAAAAAAI/AAAAAAAABk0/yIM0TD9Yvkw/s50-c-k-no/photo.jpg",
      "userId": "112463997337140462432"
     },
     "user_tz": -60
    },
    "id": "GEhgdFpCblSk",
    "outputId": "0c0042ad-af32-49b1-b8af-547ae451c4d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "tcmalloc: large alloc 1073750016 bytes == 0x5b0fa000 @  0x7fa6645781c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
      "Requirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
      "Requirement not upgraded as not directly required: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.3)\n",
      "Requirement not upgraded as not directly required: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement not upgraded as not directly required: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.1.0)\n",
      "Installing collected packages: torch\n",
      "  Found existing installation: torch 0.3.0.post4\n",
      "    Uninstalling torch-0.3.0.post4:\n",
      "      Successfully uninstalled torch-0.3.0.post4\n",
      "Successfully installed torch-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jA3PNVvDbhOY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from google.colab import files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1526063434016,
     "user": {
      "displayName": "Lukas Mosser",
      "photoUrl": "//lh6.googleusercontent.com/-TeSv83-LAiI/AAAAAAAAAAI/AAAAAAAABk0/yIM0TD9Yvkw/s50-c-k-no/photo.jpg",
      "userId": "112463997337140462432"
     },
     "user_tz": -60
    },
    "id": "lVusRQPhbhOh",
    "outputId": "c92535b6-06a6-46fa-c80a-27160eb2297e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbb60cd40b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set random seed \n",
    "torch.manual_seed(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1562,
     "status": "ok",
     "timestamp": 1526063435951,
     "user": {
      "displayName": "Lukas Mosser",
      "photoUrl": "//lh6.googleusercontent.com/-TeSv83-LAiI/AAAAAAAAAAI/AAAAAAAABk0/yIM0TD9Yvkw/s50-c-k-no/photo.jpg",
      "userId": "112463997337140462432"
     },
     "user_tz": -60
    },
    "id": "UW3-u3eVbhOy",
    "outputId": "961924f2-2920-4687-e1f8-137b973d5a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Get the CIFAR10 train images \n",
    "cifar = datasets.CIFAR10('./data/cifar/', train = True, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "__9TwJfkbhPr"
   },
   "outputs": [],
   "source": [
    "# Organize training data in batches, \n",
    "# normalize them to have values between [-1, 1] (?)\n",
    "\n",
    "train_images = torch.utils.data.DataLoader ( datasets.CIFAR10('./data/cifar/', train = True, download=False,\n",
    "                               transform=transforms.Compose([\n",
    "                               #transforms.Resize(64), \n",
    "                               #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               transforms.ToTensor(),])) , \n",
    "                               batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MM9x0OcybhQC"
   },
   "source": [
    "## Model\n",
    "\n",
    "We will use the arquitecture suggested by [Radford et al](https://arxiv.org/abs/1511.06434) for both the encoder and decoder. With convolutional layers in the encoder and fractionally-strided  convolutions  in  the  decoder.   In  each convolutional layer in the encoder we double the number of filters present in the previous layer and use a convolutional stride of 2.  In each convolutional layer in the decoder we use a fractional stride of 2 and halve the number of filters on each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ak6TO1QubhQF"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, image_size ,  hidden_dim , encoding_dim):\n",
    "        \n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.image_size = image_size\n",
    "        self.hidden_dim = hidden_dim \n",
    "        \n",
    "        # Decoder - Fractional strided convolutional layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, 1, 0, bias = False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1, bias = False),\n",
    "            nn.Sigmoid() # nn.Tanh()  \n",
    "        )\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1, bias = False),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 0, bias = False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Fully-connected layers\n",
    "        self.fc1 = nn.Linear(256, self.hidden_dim)\n",
    "        self.fc21 = nn.Linear(self.hidden_dim, self.encoding_dim)\n",
    "        self.fc22 = nn.Linear(self.hidden_dim, self.encoding_dim)\n",
    "        self.fc3 = nn.Linear(self.encoding_dim, self.hidden_dim)\n",
    "        self.fc4 = nn.Linear(self.hidden_dim, 256)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        h4 = F.sigmoid(self.fc4(h3))\n",
    "        return self.decoder( h4.view(z.size(0),-1,1,1) ) \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Encode \n",
    "        encoded = F.relu(self.fc1( self.encoder(x).view(x.size(0), -1) ) )\n",
    "        \n",
    "        #Obtain mu and logvar\n",
    "        mu = self.fc21( encoded )\n",
    "        logvar = self.fc22 ( encoded )\n",
    "        \n",
    "        #Reparametrization trick\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = eps.mul(std).add_(mu)\n",
    "        \n",
    "        # Decode \n",
    "        decoded = self.decode(z)\n",
    "\n",
    "        # return decoded, mu, logvar\n",
    "        return decoded, mu , logvar\n",
    "\n",
    "    \n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jf8M_sVvbhQO"
   },
   "outputs": [],
   "source": [
    "#Define model\n",
    "model = VAE(32, 128, 32).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
    "\n",
    "#Train model\n",
    "def train(epoch):\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_images):\n",
    "        data = Variable(data).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_images.dataset),\n",
    "                100. * batch_idx / len(train_images),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_images.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xNKLtFStbhQa",
    "outputId": "886e577d-e1d0-414e-e3a8-47f46ed86714"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs):\n",
    "    train(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, 32).cuda()\n",
    "        sample = model.decode(sample)\n",
    "        torchvision.utils.save_image(sample.view(64, 3, 32, 32),'./sample_' + str(epoch) + '.png')\n",
    "        files.download('./sample_' + str(epoch) + '.png')\n",
    "        torch.save(model.cpu().state_dict(), \"./vae_checkpoint_epoch_\"+str(epoch)+\".pth\")\n",
    "        files.download(\"./vae_checkpoint_epoch_\"+str(epoch)+\".pth\")\n",
    "        model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "o0ZE2v9gfOcI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hvgQbEHubhQo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "kuuMRPqQbhQw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "VAE-baseline-CIFAR10.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
